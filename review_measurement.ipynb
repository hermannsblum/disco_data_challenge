{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ydc.tools.import_data import import_businesses, import_reviews\n",
    "from ydc.features.get_features import get_features\n",
    "import datetime as dt\n",
    "from random import sample\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported reviews with columns ['business_id' 'date' 'stars' 'real_date']\n"
     ]
    }
   ],
   "source": [
    "(features, df, box, combos, cells, n_ind, n_dist) = get_features(status=True, new_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported reviews with columns ['business_id' 'date' 'review_id' 'stars' 'text' 'type' 'user_id' 'votes'\n",
      " 'real_date']\n"
     ]
    }
   ],
   "source": [
    "df_rev = import_reviews(new_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latest_date = df_rev.groupby('business_id')['real_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_year(date_series):\n",
    "    threshold = date_series.max() - dt.timedelta(days=360)\n",
    "    return (date_series > threshold).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df_rev.groupby('business_id')['real_date'].agg({'count': one_year})\n",
    "result = grouped['count'].apply(lambda x: x.nanosecond)  # Pandas is stupid and interpreted the sum as a timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_res = df.join(result, on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def divide_good_and_bad(dataframe, combos, key_feature, percentage):\n",
    "    \"\"\"\n",
    "    Take the given percentage of the dataframe and mark them as \"good\"\n",
    "    Done for each category separately, sort by column \"key_feature\"\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialize dataframe sorted by stars and setup new column \"good\" with False as default\n",
    "    dataframe = dataframe.sort(columns=key_feature, ascending=False)\n",
    "    dataframe['good'] = False\n",
    "    \n",
    "    for combo in combos:\n",
    "        # Every (super/sub) category combo\n",
    "        total = (df['category']==combo).sum()\n",
    "        \n",
    "        # Find n (total number times percentage)\n",
    "        num_good = int(round(total * percentage))\n",
    "        dataframe['good']\n",
    "        \n",
    "        # Get index from best n\n",
    "        idx = dataframe.loc[df['category']==combo, :].head(num_good).index\n",
    "        \n",
    "        # Set those best ones to true\n",
    "        dataframe.loc[idx, 'good'] = True\n",
    "    \n",
    "    # Restore correct order (sorting scrambled it)\n",
    "    return dataframe.sort_index()\n",
    "\n",
    "def divide(dataframe, combos, key_feature, n_classes):\n",
    "    \"\"\"\n",
    "    Divide into n classes\n",
    "    Done for each category separately, sort by column \"key_feature\"\n",
    "    0 is best, n_classes-1 worst\n",
    "    \"\"\"\n",
    "    # Initialize dataframe sorted by stars and setup new column \"good\" with False as default\n",
    "    dataframe = dataframe.sort(columns=key_feature, ascending=False)\n",
    "    dataframe['good'] = n_classes-1\n",
    "    \n",
    "    for combo in combos:\n",
    "        # Every (super/sub) category combo\n",
    "        total = (df['category']==combo).sum()\n",
    "        # Find number per class, they are all equally big\n",
    "        n_each = int(round(total / n_classes))\n",
    "        \n",
    "        # Get index \n",
    "        idx = dataframe.loc[df['category']==combo, :].index.tolist()\n",
    "        \n",
    "        for n in range(n_classes-1):\n",
    "            class_idx = idx[(n * n_each):((n + 1) * n_each)]\n",
    "            dataframe.loc[class_idx, 'good'] = n\n",
    "    \n",
    "    # Restore correct order (sorting scrambled it)\n",
    "    return dataframe.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "businesses = divide(df_res, combos, 'count', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = df_res.groupby(\"category\")['city'].count()\n",
    "combo = test.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitness_one(features, df_busi, combo, test_portion, test_rounds, c, gamma status=False):\n",
    "    features = (features - features.mean()) / features.std()\n",
    "\n",
    "    score = []\n",
    "    idx = df_busi[df_busi['category'] == combo].index.tolist()\n",
    "\n",
    "    for _ in range(test_rounds):\n",
    "        # Take out 15% of data as random sample to test data with\n",
    "        idx_sample = sample(idx, round(len(idx)*test_portion))\n",
    "        idx_train = [index for index in idx if index not in idx_sample]\n",
    "\n",
    "        subcat_clf = svm.SVC(cache_size=2000, C=c, gamma=gamma, kernel='rbf')\n",
    "\n",
    "        feat_train = features.loc[idx_train, :].values\n",
    "        quality_train = df_busi.loc[idx_train, 'good'].values  \n",
    "\n",
    "        feat_sample = features.loc[idx_sample, :].values\n",
    "        quality_sample = df_busi.loc[idx_sample, 'good'].values  \n",
    "\n",
    "        subcat_clf.fit(feat_train, quality_train)\n",
    "        score.append(subcat_clf.score(feat_sample, quality_sample))\n",
    "\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fitness_one() takes from 5 to 6 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3415eadaedef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfitness_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbusinesses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fitness_one() takes from 5 to 6 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "fitness_one(features, businesses, combo, 0.1, 10, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitness(features, df_busi, combos, test_portion, test_rounds, status=False):\n",
    "    tot_results = []\n",
    "    for combo in combos:\n",
    "        try:\n",
    "            weight = df_busi.loc[df_busi['category']==combo, 'city'].count()\n",
    "            score = fitness_one(features, df_busi, combo, test_portion, test_rounds, status)\n",
    "            tot_results.append((score, weight))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    tot_score = 0\n",
    "    tot_weight = 0    \n",
    "    for item in tot_results:\n",
    "        if item[1]==0:\n",
    "            continue  # ignore \n",
    "        tot_score += item[0] * item[1]\n",
    "        tot_weight += item[1]\n",
    "        \n",
    "    return tot_score/tot_weight\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58519942046426543"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitness(features, businesses, combos, 0.4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "%matplotlib inline\n",
    "\n",
    "C_range = np.logspace(-3, 3, 5)\n",
    "gamma_range = np.logspace(-6, -2, 5)\n",
    "\n",
    "y = target\n",
    "X = data\n",
    "\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(y, n_iter=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(svm.SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))\n",
    "\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "# plot the scores of the grid\n",
    "# grid_scores_ contains parameter settings and scores\n",
    "# We extract just the scores\n",
    "scores = [x[1] for x in grid.grid_scores_]\n",
    "scores = np.array(scores).reshape(len(C_range), len(gamma_range))\n",
    "\n",
    "# Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "#\n",
    "# The score are encoded as colors with the hot colormap which varies from dark\n",
    "# red to bright yellow. As the most interesting scores are all located in the\n",
    "# 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "# as to make it easier to visualize the small variations of score values in the\n",
    "# interesting range while not brutally collapsing all the low score values to\n",
    "# the same color.\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "plt.imshow(scores, interpolation='nearest', cmap=plt.cm.hot,\n",
    "           norm=MidpointNormalize(vmin=0.2, midpoint=0.92))\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "plt.yticks(np.arange(len(C_range)), C_range)\n",
    "plt.title('Validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "# Machine\n",
    "clf = svm.SVC(kernel='rbf', C=1, gamma=0.001)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Data\n",
    "businesses = divide(df_res, combos, 'count', 2)\n",
    "idx = (businesses['category'] == combo)\n",
    "data = features.loc[idx, :].values\n",
    "target = businesses.loc[idx, 'good'].values\n",
    "\n",
    "# Go\n",
    "cv = StratifiedShuffleSplit(target, n_iter=5, test_size=0.2, random_state=42)\n",
    "data = scaler.fit_transform(data)\n",
    "scores = cross_validation.cross_val_score(clf, data, target, cv=cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "businesses = divide(df_res, combos, 'count', 2)\n",
    "\n",
    "# Random forest\n",
    "clf = RandomForestClassifier(n_estimators=10, max_features=1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Data\n",
    "idx = (businesses['category'] == combo)\n",
    "data = features.loc[idx, :].values\n",
    "target = businesses.loc[idx, 'good'].values\n",
    "\n",
    "# Go\n",
    "cv = StratifiedShuffleSplit(target, n_iter=5, test_size=0.2, random_state=42)\n",
    "data = scaler.fit_transform(data)\n",
    "scores = cross_validation.cross_val_score(clf, data, target, cv=cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviews_mean                    0.058204\n",
       "reviews_sum                     0.057223\n",
       "reviews_std                     0.055087\n",
       "reviews_median                  0.042378\n",
       "stars_std                       0.042105\n",
       "stars_sum                       0.041601\n",
       "weighted review-count           0.041269\n",
       "stars_mean                      0.039915\n",
       "reviews_max                     0.037571\n",
       "neighbourhood_radius_squared    0.036353\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10)\n",
    "clf.fit(data, target)\n",
    "feat_names = features.columns\n",
    "feat_weights = clf.feature_importances_\n",
    "feat_series = pd.Series(feat_weights, index=feat_names)\n",
    "feat_series.sort(ascending=False)\n",
    "feat_series[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
